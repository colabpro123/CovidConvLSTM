{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Covidx",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PH3TjvOEFqai"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJAL8wRSYsYj"
      },
      "outputs": [],
      "source": [
        "!mkdir ~/.kaggle\n",
        "\n",
        "!cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcnY_UV-YsV_"
      },
      "outputs": [],
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-gHZIvSZ5TV"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d andyczhao/covidx-cxr2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPwxAh21ZDyl"
      },
      "outputs": [],
      "source": [
        "!unzip covidx-cxr2.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ErI7Zqg96Ru"
      },
      "outputs": [],
      "source": [
        "import os,glob\n",
        "import numpy as np\n",
        "import cv2\n",
        "import glob\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "import argparse\n",
        "import re\n",
        "import datetime\n",
        "from tensorflow.keras.layers import  Input,Conv2D,BatchNormalization,Activation,Subtract,LeakyReLU,Add,Average,Lambda,MaxPool2D,Dropout,UpSampling2D,Concatenate,Multiply,GlobalAveragePooling2D,Dense,ZeroPadding2D,AveragePooling2D\n",
        "from tensorflow.keras.layers import concatenate,Flatten,Layer,ReLU, MaxPooling2D\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.svm import LinearSVC\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import loadtxt\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from skimage.feature import hog,local_binary_pattern\n",
        "from skimage import data, exposure\n",
        "from skimage.transform import radon, rescale\n",
        "from skimage.filters import roberts, sobel, scharr, prewitt\n",
        "from skimage import feature\n",
        "import os,glob\n",
        "import numpy as np\n",
        "import cv2\n",
        "import glob\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "import argparse\n",
        "import re\n",
        "import datetime\n",
        "from tensorflow.keras.layers import  Input,Conv2D,BatchNormalization,Activation,Subtract,LeakyReLU,Add,Average,Lambda,MaxPool2D,Dropout,UpSampling2D,Concatenate,Multiply,GlobalAveragePooling2D,Dense,ZeroPadding2D,AveragePooling2D\n",
        "from tensorflow.keras.layers import concatenate,Flatten,ConvLSTM2D,LayerNormalization,GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import Sequential\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.svm import LinearSVC\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import loadtxt\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from skimage.feature import hog,local_binary_pattern\n",
        "from skimage import data, exposure\n",
        "from tensorflow.keras.layers import Layer "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5vvwnFRQvmE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "train_files = []\n",
        "train_dir = \"/content/train/\"\n",
        "dir_png = os.path.join(train_dir,\"*.png\")\n",
        "dir_jpg = os.path.join(train_dir,\"*.jpg\")\n",
        "dir_jpeg = os.path.join(train_dir,\"*.jpeg\")\n",
        "png_files = glob.glob(dir_png)\n",
        "jpg_files = glob.glob(dir_jpg)\n",
        "jpeg_files = glob.glob(dir_jpeg)\n",
        "train_files.extend(png_files)\n",
        "train_files.extend(jpg_files)\n",
        "train_files.extend(jpeg_files)\n",
        "train_files.sort()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PnaCMmdKDI7"
      },
      "outputs": [],
      "source": [
        "len(train_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vIQ5_NBhZwb"
      },
      "outputs": [],
      "source": [
        "dic = {}\n",
        "for j in range(len(train_files)):\n",
        "  b = train_files[j].split(\"/\")[-1]\n",
        "  dic[b] = train_files[j]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5Q7mWtMOaN6"
      },
      "outputs": [],
      "source": [
        "with open('/content/train.txt') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "titles = []\n",
        "for i in range(len(lines)):\n",
        "  a = lines[i].split(\" \")\n",
        "  titles.append(a[2])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltd4CXy3OjbT"
      },
      "outputs": [],
      "source": [
        "set(titles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQ_kfcUXgr6o"
      },
      "outputs": [],
      "source": [
        "with open('/content/train.txt') as f:\n",
        "    lines = f.readlines()\n",
        "covid_train = []\n",
        "Noncovid_train = []\n",
        "for i in range(len(lines)):\n",
        "  a = lines[i].split(\" \")\n",
        "  if a[2] == \"positive\":\n",
        "      try:\n",
        "          covid_train.append(dic[a[1]])\n",
        "      except:\n",
        "          print(\"oops\")  \n",
        "      \n",
        "  else:\n",
        "      try:\n",
        "          Noncovid_train.append(dic[a[1]])\n",
        "      except:\n",
        "          print(a[1]) \n",
        "\n",
        "covid_train.sort()\n",
        "Noncovid_train.sort()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vT6_zlbZIztk"
      },
      "outputs": [],
      "source": [
        "print(len(covid_train),len(Noncovid_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9t413jYRi2YS"
      },
      "outputs": [],
      "source": [
        "train_dic = {}\n",
        "for f in covid_train[:14841]:\n",
        "  train_dic[f] = [1,0]\n",
        "for f in Noncovid_train[:12591]:\n",
        "  train_dic[f] = [0,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4J5vgM4kxFFl"
      },
      "outputs": [],
      "source": [
        "val_dic = {}\n",
        "for f in covid_train[14841:]:\n",
        "  val_dic[f] = [1,0]\n",
        "for f in Noncovid_train[12591:]:\n",
        "  val_dic[f] = [0,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbTICb7XxLlF"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "l_val = list(val_dic.items())\n",
        "random.Random(4).shuffle(l_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TJJ5TtyxTiq"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "l = list(train_dic.items())\n",
        "random.Random(4).shuffle(l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yxFjn0vGx8e"
      },
      "outputs": [],
      "source": [
        "len(l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DjCco04yIfo"
      },
      "outputs": [],
      "source": [
        "def parse_image(l_i):\n",
        "  filename,label = l_i\n",
        "  image = tf.io.read_file(filename)\n",
        "  image = tf.image.decode_image(image)\n",
        "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "  image = tf.image.resize(image, [224, 224])\n",
        "#   image = tf.concat([image,image,image],axis = -1)\n",
        "  return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "To7Uf_xzAHca"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "\n",
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, list_dic, batch_size):\n",
        "        'Initialization'\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        self.list_dic = list_dic\n",
        "   \n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.list_dic) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        list_dic_temp = []\n",
        "        for k in range(index*self.batch_size,(index+1)*self.batch_size):\n",
        "            list_dic_temp.append(self.list_dic[k])\n",
        "        X, y = self.__data_generation(list_dic_temp)\n",
        "        return X, y\n",
        "\n",
        "    def __data_generation(self, list_dic):\n",
        "        'Generates data containing batch_size samples'\n",
        "\n",
        "        x = []\n",
        "        y = []\n",
        "\n",
        "        for filename,label in (list_dic):\n",
        "     \n",
        "            img = cv2.imread(filename)\n",
        "            img = cv2.resize(img,(224,224),interpolation = cv2.INTER_CUBIC)\n",
        "            img = img.astype('float32')/255.0\n",
        "            x.append(img)\n",
        "            y.append(label)\n",
        "        return np.asarray(x), np.asarray(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdiuxgWaJSO3"
      },
      "outputs": [],
      "source": [
        "l_dataset = DataGenerator(l,16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4vfnngOJXIU"
      },
      "outputs": [],
      "source": [
        "x,y = l_dataset.__getitem__(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afE8m9uZKsz1"
      },
      "outputs": [],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MU9tGDWO4Ppn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "test_files = []\n",
        "test_dir = \"/content/test/\"\n",
        "dir_png = os.path.join(test_dir,\"*.png\")\n",
        "dir_jpg = os.path.join(test_dir,\"*.jpg\")\n",
        "dir_jpeg = os.path.join(test_dir,\"*.jpeg\")\n",
        "png_files = glob.glob(dir_png)\n",
        "jpg_files = glob.glob(dir_jpg)\n",
        "jpeg_files = glob.glob(dir_jpeg)\n",
        "test_files.extend(png_files)\n",
        "test_files.extend(jpg_files)\n",
        "test_files.extend(jpeg_files)\n",
        "test_files.sort()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGKRr2jdDORg"
      },
      "outputs": [],
      "source": [
        "len(test_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSzKzrLr4Ppq"
      },
      "outputs": [],
      "source": [
        "dic = {}\n",
        "for j in range(len(test_files)):\n",
        "  b = test_files[j].split(\"/\")[-1]\n",
        "  dic[b] = test_files[j]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsbJxX5RDUKJ"
      },
      "outputs": [],
      "source": [
        "with open('/content/test.txt') as f:\n",
        "    lines = f.readlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoRhL43iDbB6"
      },
      "outputs": [],
      "source": [
        "lines[0].split(\" \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTMiWwkP4Ppr"
      },
      "outputs": [],
      "source": [
        "covid_test = []\n",
        "Noncovid_test = []\n",
        "for i in range(len(lines)):\n",
        "  a = lines[i].split(\" \")\n",
        "  if a[2] == \"positive\": \n",
        "    covid_test.append(dic[a[1]])\n",
        "  else:\n",
        "    try:\n",
        "      Noncovid_test.append(dic[a[1]])\n",
        "    except:\n",
        "      print(a[1]) \n",
        "covid_test.sort()\n",
        "Noncovid_test.sort()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jE0LQXMhDl2i"
      },
      "outputs": [],
      "source": [
        "len(covid_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkWpl-zA4Ppr"
      },
      "outputs": [],
      "source": [
        "test_dic = {}\n",
        "for f in covid_test:\n",
        "  test_dic[f] = [1,0]\n",
        "for f in Noncovid_test:\n",
        "  test_dic[f] = [0,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npMjb49i4Ppr"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "l = list(test_dic.items())\n",
        "random.Random(4).shuffle(l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hd8xuad_GyQh"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import numpy as np\n",
        "import keras\n",
        "from skimage.filters import roberts, sobel, scharr, prewitt\n",
        "covid_dic_list = {}\n",
        "data = []\n",
        "labels = []\n",
        "for i in range(len(l)):\n",
        "  file_name,label = l[i]\n",
        "  img = cv2.imread(file_name)\n",
        "  img0 = cv2.imread(file_name,0)   \n",
        "  try:\n",
        "    img = np.asarray(img)\n",
        "    img = cv2.resize(img,(224,224),interpolation = cv2.INTER_CUBIC)\n",
        "    img = img.astype('float32')/255.0\n",
        "    data.append(img)\n",
        "    labels.append(label)\n",
        "  except:\n",
        "    print(i,file_name)\n",
        "    print(\"Not possible\")        \n",
        "test3_data = np.array(data)\n",
        "print(test3_data.shape)\n",
        "test3_labels = np.array(labels)\n",
        "print(test3_labels.shape)  \n",
        "print('^_^-training data finished-^_^')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUiiX5u7QOHv"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import numpy as np\n",
        "import keras\n",
        "from skimage.filters import roberts, sobel, scharr, prewitt\n",
        "\n",
        "covid_dic_list = {}\n",
        "data = []\n",
        "labels = []\n",
        "for i in range(len(l_val)):\n",
        "  file_name,label = l_val[i]\n",
        "  img = cv2.imread(file_name)\n",
        "  img0 = cv2.imread(file_name,0)     \n",
        "  try:\n",
        "    img = np.asarray(img)\n",
        "    img = cv2.resize(img,(224,224),interpolation = cv2.INTER_CUBIC)\n",
        "    img = img.astype('float32')/255.0\n",
        "    data.append(img)\n",
        "    labels.append(label)\n",
        "  except:\n",
        "    print(i,file_name)\n",
        "    print(\"Not possible\")  \n",
        "       \n",
        "val3_data = np.array(data)\n",
        "print(val3_data.shape)\n",
        "val3_labels = np.array(labels)\n",
        "print(val3_labels.shape)  \n",
        "print('^_^-validation data finished-^_^')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yrM0d5HSXukw"
      },
      "outputs": [],
      "source": [
        "inception_model = tf.keras.applications.InceptionV3(include_top=False,weights='imagenet',classes = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xmUit-QXukw"
      },
      "outputs": [],
      "source": [
        "inception_model.trainable = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMamiheAXukx"
      },
      "outputs": [],
      "source": [
        "inputs = tf.keras.Input(shape=(224,224,3))\n",
        "x = inception_model(inputs)\n",
        "input_ = tf.expand_dims(x,axis = 1)\n",
        "nb_chan = 512\n",
        "ratio = 16\n",
        "x3 = ConvLSTM2D(filters=512, kernel_size=(1,1),padding = \"same\")(input_) \n",
        "x3 = BatchNormalization(axis=3, momentum=0.0,epsilon=0.0001)(x3)\n",
        "x3 = Activation('relu')(x3)\n",
        "\n",
        "y = tf.keras.layers.GlobalAveragePooling2D()(x3)\n",
        "y = tf.keras.layers.Dense(nb_chan // ratio, activation='relu')(y)\n",
        "y = tf.keras.layers.Dense(nb_chan, activation='sigmoid')(y)\n",
        "y_3 = tf.keras.layers.Multiply()([x3, y])\n",
        "\n",
        "ratio = 16\n",
        "flat = Flatten()(y_3)\n",
        "\n",
        "dense_1 = Dense(4096,activation = 'relu')(flat)\n",
        "dense_2 = Dense(4096,activation = 'relu')(dense_1)\n",
        "prediction = Dense(2,activation = 'softmax')(dense_2)\n",
        "inception_pred = Model(inputs = inputs,outputs = prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dotIJk3aSitz"
      },
      "outputs": [],
      "source": [
        "inception_pred.compile(optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.00002), loss=tf.keras.losses.CategoricalCrossentropy(from_logits = False) , metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azk8EJ7oL9CX"
      },
      "outputs": [],
      "source": [
        "inception_pred.fit(l_dataset,epochs = 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C627RGSBXuky"
      },
      "outputs": [],
      "source": [
        "inception_pred.evaluate(test3_data,test3_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_gG-KQPt8iU"
      },
      "outputs": [],
      "source": [
        "inception_pred.load_weights(\"fintune-10-covidx-inception_combined.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-6AZNN3WJbx"
      },
      "outputs": [],
      "source": [
        "vgg_model = tf.keras.applications.VGG19(include_top=False,weights='imagenet',classes = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gh9Q4tPWJb7"
      },
      "outputs": [],
      "source": [
        "vgg_model.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fbNcoBfWJb7"
      },
      "outputs": [],
      "source": [
        "inputs = tf.keras.Input(shape=(224,224,3))\n",
        "x = vgg_model(inputs)\n",
        "input_ = tf.expand_dims(x,axis = 1)\n",
        "nb_chan = 512\n",
        "ratio = 16\n",
        "x3 = ConvLSTM2D(filters=512, kernel_size=(1,1),padding = \"same\")(input_) \n",
        "x3 = BatchNormalization(axis=3, momentum=0.0,epsilon=0.0001)(x3)\n",
        "x3 = Activation('relu')(x3)\n",
        "\n",
        "y = tf.keras.layers.GlobalAveragePooling2D()(x3)\n",
        "y = tf.keras.layers.Dense(nb_chan // ratio, activation='relu')(y)\n",
        "y = tf.keras.layers.Dense(nb_chan, activation='sigmoid')(y)\n",
        "y_3 = tf.keras.layers.Multiply()([x3, y])\n",
        "\n",
        "ratio = 16\n",
        "flat = Flatten()(y_3)\n",
        "\n",
        "dense_1 = Dense(4096,activation = 'relu')(flat)\n",
        "dense_2 = Dense(4096,activation = 'relu')(dense_1)\n",
        "prediction = Dense(2,activation = 'softmax')(dense_2)\n",
        "vgg_pred = Model(inputs = inputs,outputs = prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tj_lk062WJb8"
      },
      "outputs": [],
      "source": [
        "vgg_pred.summary()\n",
        "vgg_pred.compile(optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.0002), loss=tf.keras.losses.CategoricalCrossentropy(from_logits = False) , metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AV5hr3VgWJb8"
      },
      "outputs": [],
      "source": [
        "vgg_pred.fit(l_dataset,epochs = 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfePAM5iWJb8",
        "outputId": "0494a3f0-6c34-43ef-83c2-fbadd3ebf970"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "13/13 [==============================] - 6s 205ms/step - loss: 14.4267 - accuracy: 0.8350\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[14.426671981811523, 0.8349999785423279]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vgg_pred.evaluate(test3_data,test3_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "noB0sQLzWXwe"
      },
      "outputs": [],
      "source": [
        "vgg_pred.load_weights(\"covidx-vgg_combined.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cklNVHb9H4Ag"
      },
      "outputs": [],
      "source": [
        "mobile_model = tf.keras.applications.MobileNet(input_shape=(224,224,3),include_top=False,weights='imagenet',classes = 2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mobile_model.summary()"
      ],
      "metadata": {
        "id": "TdzxPe0voclU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Ny1uXGOH4Aq"
      },
      "outputs": [],
      "source": [
        "mobile_model.trainable = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4JDLPm5H4Ar"
      },
      "outputs": [],
      "source": [
        "inputs = tf.keras.Input(shape=(224,224,3))\n",
        "#x = inputs\n",
        "x = mobile_model(inputs)\n",
        "input_ = tf.expand_dims(x,axis = 1)\n",
        "nb_chan = 512\n",
        "ratio = 16\n",
        "x3 = ConvLSTM2D(filters=512, kernel_size=(1,1),padding = \"same\")(input_) \n",
        "x3 = BatchNormalization(axis=3, momentum=0.0,epsilon=0.0001)(x3)\n",
        "x3 = Activation('relu')(x3)\n",
        "\n",
        "y = tf.keras.layers.GlobalAveragePooling2D()(x3)\n",
        "y = tf.keras.layers.Dense(nb_chan // ratio, activation='relu')(y)\n",
        "y = tf.keras.layers.Dense(nb_chan, activation='sigmoid')(y)\n",
        "y_3 = tf.keras.layers.Multiply()([x3, y])\n",
        "\n",
        "ratio = 16\n",
        "flat = Flatten()(y_3)\n",
        "dense_1 = Dense(4096,activation = 'relu')(flat)\n",
        "dense_2 = Dense(4096,activation = 'relu')(dense_1)\n",
        "prediction = Dense(2,activation = 'softmax')(dense_2)\n",
        "mobile_pred = Model(inputs = inputs,outputs = prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6O16as2H4As"
      },
      "outputs": [],
      "source": [
        "mobile_pred.compile(optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.00002), loss=tf.keras.losses.CategoricalCrossentropy(from_logits = False) , metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8E_upCtaH4As"
      },
      "outputs": [],
      "source": [
        "mobile_pred.fit(l_dataset,epochs = 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erxhP1f3H4At"
      },
      "outputs": [],
      "source": [
        "mobile_pred.evaluate(test3_data,test3_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PIamhp4YrLMP"
      },
      "outputs": [],
      "source": [
        "mobile_pred.load_weights(\"fintune-covidx-10-mobile_combined.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICiIvmy1v6hE"
      },
      "outputs": [],
      "source": [
        "test3 = vgg_pred.predict(test3_data)\n",
        "test4 = mobile_pred.predict(test3_data)\n",
        "test5 = inception_pred.predict(test3_data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = new_pred.predict(test3_data)\n",
        "new_test = np.argmax(test,axis = 1)\n",
        "labels = np.argmax(test3_labels,axis = 1)"
      ],
      "metadata": {
        "id": "paMXCHcZbW1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OazO9W4Kv6jO"
      },
      "outputs": [],
      "source": [
        "new_test3 = np.argmax(test3,axis = 1)\n",
        "new_test4 = np.argmax(test4,axis = 1)\n",
        "new_test5 = np.argmax(test5,axis = 1)\n",
        "labels = np.argmax(test3_labels,axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDfux4k3RIuf"
      },
      "outputs": [],
      "source": [
        "val3 = vgg_pred.predict(val3_data)\n",
        "val4 = mobile_pred.predict(val3_data)\n",
        "val5 = inception_pred.predict(val3_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2pLg5gGvRRYH"
      },
      "outputs": [],
      "source": [
        "new_val3 = np.argmax(val3,axis = 1)\n",
        "new_val4 = np.argmax(val4,axis = 1)\n",
        "new_val5 = np.argmax(val5,axis = 1)\n",
        "val_labels = np.argmax(val3_labels,axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uRLCN28KM34"
      },
      "outputs": [],
      "source": [
        "def sugeno(solution,pred1,pred2,pred3, labels):\n",
        "    fuzzymeasures = np.array([solution[0],solution[1],solution[2]])\n",
        "    l = Symbol('l', real = True)\n",
        "    lam = solve(  ( 1 + l* fuzzymeasures[0]) * ( 1 + l* fuzzymeasures[1]) *( 1 + l* fuzzymeasures[2]) - (l+1), l )\n",
        "    if len(lam) < 3:\n",
        "      lam = np.asarray(lam)\n",
        "    else:\n",
        "      if lam[0] >= 0:\n",
        "          lam = np.asarray(lam[0])\n",
        "      elif lam[1] >= 0:\n",
        "          lam = np.asarray(lam[1])\n",
        "      elif lam[2] >= 0:\n",
        "          lam = np.asarray(lam[2])\n",
        "    \n",
        "    Ypred_fuzzy = np.zeros(shape = pred1.shape, dtype = float)\n",
        "    for sample in range(0,pred1.shape[0]):\n",
        "        for classes in range(0,2):\n",
        "            scores = np.array([pred1[sample][classes],pred2[sample][classes],pred3[sample][classes]])\n",
        "            permutedidx = np.flip(np.argsort(scores))\n",
        "            scoreslambda = scores[permutedidx]\n",
        "            fmlambda = fuzzymeasures[permutedidx]\n",
        "            ge_prev = fmlambda[0]\n",
        "            fuzzyprediction = min((scoreslambda[0], fmlambda[0]))\n",
        "            for i in range(1,3):\n",
        "                ge_curr = ge_prev + fmlambda[i] + lam * fmlambda[i] * ge_prev\n",
        "                fuzzyprediction = max((fuzzyprediction,min((scoreslambda[i],ge_curr))))\n",
        "                ge_prev = ge_curr\n",
        "\n",
        "            Ypred_fuzzy[sample][classes] = fuzzyprediction\n",
        "    ypred_fuzzy = np.argmax(Ypred_fuzzy, axis=1)\n",
        "    pred_label = []\n",
        "    for i in ypred_fuzzy:\n",
        "      label = np.zeros((2))\n",
        "      label[i] = label[i]+1\n",
        "      pred_label.append(label)\n",
        "    pred_label = np.array(pred_label)\n",
        "    acc = accuracy_score(labels,pred_label)\n",
        "    #print(acc)\n",
        "    return -acc,ypred_fuzzy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EYnrOjEw7MB"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sympy.solvers import solve\n",
        "from sympy import Symbol\n",
        "import numpy as np\n",
        "# The fuzzy measure values selected by experimentally tuning on the validation set is [1.17979882,1.73704556,2.14123453]\n",
        "acc, ypred = sugeno([1.17979882,1.73704556,2.14123453],test3,test4,test5,test3_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MDu1hpousIV"
      },
      "outputs": [],
      "source": [
        "acc"
      ]
    }
  ]
}