{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dataset1",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRQk2I8f2Mg9"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/ieee8023/covid-chestxray-dataset.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Anh_P_ZhXukp"
      },
      "outputs": [],
      "source": [
        "import os,glob\n",
        "import numpy as np\n",
        "import cv2\n",
        "import glob\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "import argparse\n",
        "import re\n",
        "import datetime\n",
        "from tensorflow.keras.layers import  Input,Conv2D,BatchNormalization,Activation,Subtract,LeakyReLU,Add,Average,Lambda,MaxPool2D,Dropout,UpSampling2D,Concatenate,Multiply,GlobalAveragePooling2D,Dense,ZeroPadding2D,AveragePooling2D\n",
        "from tensorflow.keras.layers import concatenate,Flatten,ConvLSTM2D,LayerNormalization,GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import Sequential\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.svm import LinearSVC\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import loadtxt\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from skimage.feature import hog,local_binary_pattern\n",
        "from skimage import data, exposure\n",
        "from tensorflow.keras.layers import Layer "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7VtRTiQI_T2"
      },
      "outputs": [],
      "source": [
        "! pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7HfetD9I_T2"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/.kaggle\n",
        "\n",
        "! cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dk1oj48YI_T2"
      },
      "outputs": [],
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEXrWAioI_T2"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMmdkOU6FDg8"
      },
      "outputs": [],
      "source": [
        "!unzip chest-xray-pneumonia.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCdkKJUtXuku"
      },
      "outputs": [],
      "source": [
        "normal_dir = \"./covid-chestxray-dataset/images\"\n",
        "dir1 = os.path.join(normal_dir,\"*.png\")\n",
        "dir = os.path.join(normal_dir,\"*.jpg\")\n",
        "dir2 = os.path.join(normal_dir,\"*.jpeg\")\n",
        "covid_files = glob.glob(dir)\n",
        "covid_files2 = glob.glob(dir2)\n",
        "covid_files1 = glob.glob(dir1)\n",
        "covid_files.extend(covid_files2)\n",
        "covid_files.extend(covid_files1)\n",
        "print(\"Number of covid-19 files\")\n",
        "print(len(covid_files))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3unI7WL2YFBp"
      },
      "outputs": [],
      "source": [
        "normal_dir = \"/content/chest_xray/train/NORMAL\"\n",
        "dir1 = os.path.join(normal_dir,\"*.png\")\n",
        "dir2 = os.path.join(normal_dir,\"*.jpeg\")\n",
        "dir = os.path.join(normal_dir,\"*.jpg\")\n",
        "normal_files = glob.glob(dir)\n",
        "normal_1 = glob.glob(dir1)\n",
        "normal_2 = glob.glob(dir2)\n",
        "normal_files.extend(normal_1)\n",
        "normal_files.extend(normal_2)\n",
        "print(\"Number of normal files\")\n",
        "print(len(normal_files))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Sq8mVpmYG2p"
      },
      "outputs": [],
      "source": [
        "normal_dir = \"/content/chest_xray/train/PNEUMONIA\"\n",
        "dir1 = os.path.join(normal_dir,\"*.png\")\n",
        "dir2 = os.path.join(normal_dir,\"*.jpeg\")\n",
        "dir = os.path.join(normal_dir,\"*.jpg\")\n",
        "pneumonia_files = glob.glob(dir)\n",
        "pneumonia_1 = glob.glob(dir1)\n",
        "pneumonia_2 = glob.glob(dir2)\n",
        "pneumonia_files.extend(pneumonia_1)\n",
        "pneumonia_files.extend(pneumonia_2)\n",
        "print(len(pneumonia_files))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_rIzcRQYKXg"
      },
      "outputs": [],
      "source": [
        "pneumonia_files.sort()\n",
        "normal_files.sort()\n",
        "covid_files.sort()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXaUdyjvXukv"
      },
      "outputs": [],
      "source": [
        "train_dic = {}\n",
        "for f in covid_files[:665]:\n",
        "  train_dic[f] = [1,0,0]\n",
        "for f in normal_files[:965]:\n",
        "  train_dic[f] = [0,1,0]\n",
        "for f in pneumonia_files[:2790]:\n",
        "  train_dic[f] = [0,0,1]\n",
        "\n",
        "\n",
        "val_dic = {}\n",
        "for f in covid_files[665:739]:\n",
        "    val_dic[f] = [1,0,0]\n",
        "for f in normal_files[965:1072]:\n",
        "    val_dic[f] = [0,1,0]\n",
        "for f in pneumonia_files[2790:3100]:\n",
        "    val_dic[f] = [0,0,1]\n",
        "\n",
        "test_dic = {}\n",
        "for f in covid_files[739:]:\n",
        "  test_dic[f] = [1,0,0]\n",
        "for f in normal_files[1072:]:\n",
        "  test_dic[f] = [0,1,0]\n",
        "for f in pneumonia_files[3100:]:\n",
        "  test_dic[f] = [0,0,1]\n",
        "\n",
        "import random\n",
        "l = list(train_dic.items())\n",
        "random.Random(4).shuffle(l)\n",
        "l_test = list(test_dic.items())\n",
        "random.Random(4).shuffle(l_test)\n",
        "l_val = list(val_dic.items())\n",
        "random.Random(4).shuffle(l_val)\n",
        "print(len(l),len(l_test),len(l_val))\n",
        "\n",
        "\n",
        "covid_dic_list = {}\n",
        "data = []\n",
        "data_112 = []\n",
        "data_56 = []\n",
        "data_256 = []\n",
        "labels = []\n",
        "for i in range(len(l)):\n",
        "  file_name,label = l[i]\n",
        "  img = cv2.imread(file_name)\n",
        "  try:\n",
        "    img = cv2.resize(img,(224,224),interpolation = cv2.INTER_CUBIC)\n",
        "    img = img.astype('float32')/255.0\n",
        "    data.append(img)\n",
        "    labels.append(label)\n",
        "\n",
        "  except:\n",
        "    print(i,file_name)\n",
        "    print(\"Not possible\")  \n",
        "       \n",
        "train_data = np.array(data)\n",
        "print(\"Shape of training data\")\n",
        "print(train_data.shape)\n",
        "train_labels = np.array(labels)\n",
        "print(\"Shape of training labels\")\n",
        "print(train_labels.shape)    \n",
        "print('^_^-training data finished-^_^')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtqoSB16ewn5"
      },
      "outputs": [],
      "source": [
        "\n",
        "data = []\n",
        "labels = []\n",
        "for i in range(len(l_val)):\n",
        "  file_name,label = l_val[i]\n",
        "  img = cv2.imread(file_name)\n",
        "  try:\n",
        "    img = cv2.resize(img,(224,224),interpolation = cv2.INTER_CUBIC)  \n",
        "    img = img.astype('float32')/255.0\n",
        "    data.append(img)\n",
        "    labels.append(label)\n",
        "  except:\n",
        "    print(file_name,i)  \n",
        " \n",
        "val_data = np.array(data)\n",
        "print(\"Shape of validation data\")\n",
        "print(val_data.shape)\n",
        "\n",
        "val_labels = np.array(labels)\n",
        "print(\"Shape of validation data\")\n",
        "print(val_labels.shape)    \n",
        "print('^_^-testing data finished-^_^')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOlGkzSjXukx"
      },
      "outputs": [],
      "source": [
        "\n",
        "data = []\n",
        "labels = []\n",
        "for i in range(len(l_test)):\n",
        "  file_name,label = l_test[i]\n",
        "  img = cv2.imread(file_name)\n",
        "  try:\n",
        "    img = cv2.resize(img,(224,224),interpolation = cv2.INTER_CUBIC)\n",
        "    img = img.astype('float32')/255.0\n",
        "    data.append(img)\n",
        "    labels.append(label)\n",
        "  except:\n",
        "    print(file_name,i)  \n",
        " \n",
        "test_data = np.array(data)\n",
        "print(\"Shape of testing data\")\n",
        "print(test_data.shape)\n",
        "\n",
        "test_labels = np.array(labels)\n",
        "print(\"Shape of testing data\")\n",
        "print(test_labels.shape)    \n",
        "print('^_^-testing data finished-^_^')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXaRlHOKqiPY"
      },
      "outputs": [],
      "source": [
        "inception_model = tf.keras.applications.InceptionV3(include_top=False,weights='imagenet',classes = 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VM-uN2TqiPY"
      },
      "outputs": [],
      "source": [
        "inception_model.trainable = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBSOLReXqiPZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "inputs = tf.keras.Input(shape=(224,224,3))\n",
        "\n",
        "x = inception_model(inputs)\n",
        "input_ = tf.expand_dims(x,axis = 1)\n",
        "nb_chan = 512\n",
        "ratio = 16\n",
        "x3 = ConvLSTM2D(filters=512, kernel_size=(1,1),padding = \"same\")(input_) \n",
        "x3 = BatchNormalization(axis=3, momentum=0.0,epsilon=0.0001)(x3)\n",
        "x3 = Activation('relu')(x3)\n",
        "\n",
        "\n",
        "y = tf.keras.layers.GlobalAveragePooling2D()(x3)\n",
        "y = tf.keras.layers.Dense(nb_chan // ratio, activation='relu')(y)\n",
        "y = tf.keras.layers.Dense(nb_chan, activation='sigmoid')(y)\n",
        "y_3 = tf.keras.layers.Multiply()([x3, y])\n",
        "\n",
        "ratio = 16\n",
        "flat = Flatten()(y_3)\n",
        "\n",
        "dense_1 = Dense(4096,activation = 'relu')(flat)\n",
        "dense_2 = Dense(4096,activation = 'relu')(dense_1)\n",
        "prediction = Dense(3,activation = 'softmax')(dense_2)\n",
        "inception_pred = Model(inputs = inputs,outputs = prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJuH2LreqiPZ"
      },
      "outputs": [],
      "source": [
        "inception_pred.compile(optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.0002), loss=tf.keras.losses.CategoricalCrossentropy(from_logits = False) , metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_qgWRC3qiPZ"
      },
      "outputs": [],
      "source": [
        "inception_pred.fit(train_data,train_labels,epochs =40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpeG0TEqqiPZ"
      },
      "outputs": [],
      "source": [
        "inception_pred.evaluate(test_data,test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qt-0Z818qiPa"
      },
      "outputs": [],
      "source": [
        "inception_pred.load_weights(\"/gdrive/MyDrive/config-2/final-finetune-inception_combined.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3q_KfB80G8h6"
      },
      "outputs": [],
      "source": [
        "vgg_model = tf.keras.applications.VGG19(include_top=False,weights='imagenet',classes = 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0sdih9LhG8h7"
      },
      "outputs": [],
      "source": [
        "vgg_model.trainable = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOJ1iWliG8h7"
      },
      "outputs": [],
      "source": [
        "\n",
        "inputs = tf.keras.Input(shape=(224,224,3))\n",
        "x = vgg_model(inputs)\n",
        "input_ = tf.expand_dims(x,axis = 1)\n",
        "nb_chan = 512\n",
        "ratio = 16\n",
        "x3 = ConvLSTM2D(filters=512, kernel_size=(1,1),padding = \"same\")(input_) \n",
        "x3 = BatchNormalization(axis=3, momentum=0.0,epsilon=0.0001)(x3)\n",
        "x3 = Activation('relu')(x3)\n",
        "\n",
        "y = tf.keras.layers.GlobalAveragePooling2D()(x3)\n",
        "y = tf.keras.layers.Dense(nb_chan // ratio, activation='relu')(y)\n",
        "y = tf.keras.layers.Dense(nb_chan, activation='sigmoid')(y)\n",
        "y_3 = tf.keras.layers.Multiply()([x3, y])\n",
        "\n",
        "ratio = 16\n",
        "flat = Flatten()(y_3)\n",
        "\n",
        "dense_1 = Dense(4096,activation = 'relu')(flat)\n",
        "dense_2 = Dense(4096,activation = 'relu')(dense_1)\n",
        "prediction = Dense(3,activation = 'softmax')(dense_2)\n",
        "vgg_pred = Model(inputs = inputs,outputs = prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbIXgGCxG8h7"
      },
      "outputs": [],
      "source": [
        "vgg_pred.compile(optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.00002), loss=tf.keras.losses.CategoricalCrossentropy(from_logits = False) , metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQW49y9BG8h7"
      },
      "outputs": [],
      "source": [
        "vgg_pred.fit(train_data,train_labels,epochs = 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hOgnJCfdG8h7"
      },
      "outputs": [],
      "source": [
        "vgg_pred.evaluate(test_data,test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "natEQ6EkG8h8"
      },
      "outputs": [],
      "source": [
        "vgg_pred.load_weights(\"/gdrive/MyDrive/config-2/finetune30-vgg_combined.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cm-Au3mOf36r"
      },
      "outputs": [],
      "source": [
        "mobile_model = tf.keras.applications.MobileNet(include_top=False,weights='imagenet',classes = 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NH7WwZDf36r"
      },
      "outputs": [],
      "source": [
        "mobile_model.trainable = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4RHN5xxf36r"
      },
      "outputs": [],
      "source": [
        "\n",
        "inputs = tf.keras.Input(shape=(224,224,3))\n",
        "\n",
        "x = mobile_model(inputs)\n",
        "input_ = tf.expand_dims(x,axis = 1)\n",
        "nb_chan = 512\n",
        "ratio = 16\n",
        "x3 = ConvLSTM2D(filters=512, kernel_size=(1,1),padding = \"same\")(input_) \n",
        "x3 = BatchNormalization(axis=3, momentum=0.0,epsilon=0.0001)(x3)\n",
        "x3 = Activation('relu')(x3)\n",
        "\n",
        "y = tf.keras.layers.GlobalAveragePooling2D()(x3)\n",
        "y = tf.keras.layers.Dense(nb_chan // ratio, activation='relu')(y)\n",
        "y = tf.keras.layers.Dense(nb_chan, activation='sigmoid')(y)\n",
        "y_3 = tf.keras.layers.Multiply()([x3, y])\n",
        "\n",
        "\n",
        "flat = Flatten()(y_3)\n",
        "\n",
        "dense_1 = Dense(4096,activation = 'relu')(flat)\n",
        "dense_2 = Dense(4096,activation = 'relu')(dense_1)\n",
        "prediction = Dense(3,activation = 'softmax')(dense_2)\n",
        "mobile_pred = Model(inputs = inputs,outputs = prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42XFUXkCf36r"
      },
      "outputs": [],
      "source": [
        "mobile_pred.compile(optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.0002), loss=tf.keras.losses.CategoricalCrossentropy(from_logits = False) , metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4dZD_uvf36r"
      },
      "outputs": [],
      "source": [
        "mobile_pred.fit(train_data,train_labels,epochs = 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9n1q0Walf36r"
      },
      "outputs": [],
      "source": [
        "mobile_pred.evaluate(test_data,test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AyYQv_HJf36s"
      },
      "outputs": [],
      "source": [
        "mobile_pred.load_weights(\"/gdrive/MyDrive/config-2/finetune-mobilenetv1_combined.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hdmhnCpKM34"
      },
      "outputs": [],
      "source": [
        "test3 = vgg_pred.predict(test_data)\n",
        "test4 = mobile_pred.predict(test_data)\n",
        "test5 = inception_pred.predict(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blZIC3XBKM34"
      },
      "outputs": [],
      "source": [
        "new_test3 = np.argmax(test3,axis = 1)\n",
        "new_test4 = np.argmax(test4,axis = 1)\n",
        "new_test5 = np.argmax(test5,axis = 1)\n",
        "labels = np.argmax(test_labels,axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77qwYQnvKM34"
      },
      "outputs": [],
      "source": [
        "val3 = vgg_pred.predict(val_data)\n",
        "val4 = mobile_pred.predict(val_data)\n",
        "val5 = inception_pred.predict(val_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSRMLk_GKM34"
      },
      "outputs": [],
      "source": [
        "new_val3 = np.argmax(val3,axis = 1)\n",
        "new_val4 = np.argmax(val4,axis = 1)\n",
        "new_val5 = np.argmax(val5,axis = 1)\n",
        "vallabels = np.argmax(val_labels,axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uRLCN28KM34"
      },
      "outputs": [],
      "source": [
        "\n",
        "def sugeno(solution,pred1,pred2,pred3, labels):\n",
        "    fuzzymeasures = np.array([solution[0],solution[1],solution[2]])\n",
        "    l = Symbol('l', real = True)\n",
        "    lam = solve(  ( 1 + l* fuzzymeasures[0]) * ( 1 + l* fuzzymeasures[1]) *( 1 + l* fuzzymeasures[2]) - (l+1), l )\n",
        "    if len(lam) < 3:\n",
        "      lam = np.asarray(lam)\n",
        "    else:\n",
        "      if lam[0] >= 0:\n",
        "          lam = np.asarray(lam[2])\n",
        "      elif lam[1] >= 0:\n",
        "          lam = np.asarray(lam[2])\n",
        "      elif lam[2] >= 0:\n",
        "          lam = np.asarray(lam[2])\n",
        "    \n",
        "    Ypred_fuzzy = np.zeros(shape = pred1.shape, dtype = float)\n",
        "    for sample in range(0,pred1.shape[0]):\n",
        "        for classes in range(0,3):\n",
        "            scores = np.array([pred1[sample][classes],pred2[sample][classes],pred3[sample][classes]])\n",
        "            permutedidx = np.flip(np.argsort(scores))\n",
        "            scoreslambda = scores[permutedidx]\n",
        "            fmlambda = fuzzymeasures[permutedidx]\n",
        "            ge_prev = fmlambda[0]\n",
        "            fuzzyprediction = min((scoreslambda[0], fmlambda[0]))\n",
        "            for i in range(1,3):\n",
        "                ge_curr = ge_prev + fmlambda[i] + lam * fmlambda[i] * ge_prev\n",
        "                fuzzyprediction = max((fuzzyprediction,min((scoreslambda[i],ge_curr))))\n",
        "                ge_prev = ge_curr\n",
        "\n",
        "            Ypred_fuzzy[sample][classes] = fuzzyprediction\n",
        "    ypred_fuzzy = np.argmax(Ypred_fuzzy, axis=1)\n",
        "    pred_label = []\n",
        "    for i in ypred_fuzzy:\n",
        "      label = np.zeros((3))\n",
        "      label[i] = label[i]+1\n",
        "      pred_label.append(label)\n",
        "    pred_label = np.array(pred_label)\n",
        "    acc = accuracy_score(labels,pred_label)\n",
        "    #print(acc)\n",
        "    return -acc, ypred_fuzzy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5W42fPQiKM34"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sympy.solvers import solve\n",
        "from sympy import Symbol\n",
        "import numpy as np\n",
        "# The fuzzy measure values selected by experimentally tuning on the validation set is [0.99076804,1.17916025,0.87506916]\n",
        "acc, ypred_fuzzy = sugeno([0.99076804,1.17916025,0.87506916],test3,test4,test5,test_labels)"
      ]
    }
  ]
}